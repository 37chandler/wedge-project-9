{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wedge Task 3\n",
    "___\n",
    "The third task of this project involves building several summary text files and populate a relational database using these files.\n",
    "### Connect to GBQ\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import gc\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Summary Tables\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query_to_file(query, filename):\n",
    "    try:\n",
    "        # Execute the query\n",
    "        query_job = client.query(query)\n",
    "        # Convert the query results to a list of dictionaries\n",
    "        results = [dict(row) for row in query_job]\n",
    "        # Convert the results into a pandas DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        # Save to a txt file in the data folder\n",
    "        results_df.to_csv(filename, index=False, sep=';')\n",
    "        # Memory management\n",
    "        del results, results_df\n",
    "        gc.collect()\n",
    "        # Success message\n",
    "        print(\"File saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First File\n",
    "___\n",
    "Sales by date by hour: By calendar date (YYYY-MM-DD) and hour of the day determine the total spend in the store, the number of transactions, and a count of the number of items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "query1 = \"\"\"\n",
    "SELECT EXTRACT(DATE FROM CAST(datetime AS DATETIME)) AS date,\n",
    "       EXTRACT(HOUR FROM CAST(datetime AS DATETIME)) AS hour,\n",
    "       SUM(total) AS spend,\n",
    "       COUNT(DISTINCT CONCAT(\n",
    "                            CAST(EXTRACT(DATE FROM CAST(datetime AS DATETIME)) AS STRING),\n",
    "                            CAST(register_no AS STRING),\n",
    "                            CAST(emp_no AS STRING),\n",
    "                            CAST(trans_no AS STRING)\n",
    "                            )\n",
    "              ) AS transactions,\n",
    "       SUM(CASE\n",
    "              WHEN trans_status IN ('V', 'R') THEN -1\n",
    "              ELSE 1\n",
    "              END\n",
    "              ) AS items\n",
    "FROM `wedge-to-the-cloud.wedge_to_the_dataset.transactions`\n",
    "WHERE department NOT IN (-1,0,15,99)\n",
    "       AND (trans_status IN (' ', '', 'V', 'R') OR trans_status IS NULL)\n",
    "GROUP BY date, hour\n",
    "ORDER BY date, hour\n",
    "\"\"\"\n",
    "\n",
    "filename1 = 'data/SummaryTables/sales_by_date_by_hour.txt'\n",
    "\n",
    "execute_query_to_file(query1, filename1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second File\n",
    "___\n",
    "Sales by owner by year by month: A file that has the following columns: card_no, year, month, sales, transactions, and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "query2 = \"\"\"\n",
    "SELECT card_no,\n",
    "       EXTRACT(YEAR FROM CAST(datetime AS DATETIME)) AS year,\n",
    "       EXTRACT(MONTH FROM CAST(datetime AS DATETIME)) AS month,\n",
    "       SUM(total) AS spend,\n",
    "       COUNT(DISTINCT CONCAT(\n",
    "                            CAST(EXTRACT(DATE FROM CAST(datetime AS DATETIME)) AS STRING),\n",
    "                            CAST(register_no AS STRING),\n",
    "                            CAST(emp_no AS STRING),\n",
    "                            CAST(trans_no AS STRING)\n",
    "                            )\n",
    "              ) AS transactions,\n",
    "       SUM(CASE\n",
    "              WHEN trans_status IN ('V', 'R') THEN -1\n",
    "              ELSE 1\n",
    "              END\n",
    "              ) AS items\n",
    "FROM `wedge-to-the-cloud.wedge_to_the_dataset.transactions`\n",
    "WHERE department NOT IN (-1,0,15,99)\n",
    "       AND (trans_status IN (' ', '', 'V', 'R') OR trans_status IS NULL)\n",
    "GROUP BY card_no, year, month\n",
    "ORDER BY card_no, year, month\n",
    "\"\"\"\n",
    "\n",
    "filename2 = 'data/SummaryTables/sales_by_owner_by_year_by_month.txt'\n",
    "\n",
    "execute_query_to_file(query2, filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third File\n",
    "___\n",
    "Sales by product description by year by month: A file that has the following columns: upc, description, department number, department name, year, month, sales, transactions, and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully.\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT upc,\n",
    "       description,\n",
    "       department,\n",
    "       EXTRACT(YEAR FROM CAST(datetime AS DATETIME)) AS year,\n",
    "       EXTRACT(MONTH FROM CAST(datetime AS DATETIME)) AS month,\n",
    "       SUM(total) AS spend,\n",
    "       COUNT(DISTINCT CONCAT(\n",
    "                            CAST(EXTRACT(DATE FROM CAST(datetime AS DATETIME)) AS STRING),\n",
    "                            CAST(register_no AS STRING),\n",
    "                            CAST(emp_no AS STRING),\n",
    "                            CAST(trans_no AS STRING)\n",
    "                            )\n",
    "              ) AS transactions,\n",
    "       SUM(CASE\n",
    "              WHEN trans_status IN ('V', 'R') THEN -1\n",
    "              ELSE 1\n",
    "              END\n",
    "              ) AS items\n",
    "FROM `wedge-to-the-cloud.wedge_to_the_dataset.transactions`\n",
    "WHERE department NOT IN (-1,0,15,99)\n",
    "       AND (trans_status IN (' ', '', 'V', 'R') OR trans_status IS NULL)\n",
    "GROUP BY upc, description, department, year, month\n",
    "ORDER BY upc, description, department, year, month\n",
    "\"\"\"\n",
    "\n",
    "filename3 = 'data/SummaryTables/sales_by_product_description_by_year_by_month.txt'\n",
    "\n",
    "execute_query_to_file(query3, filename3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Database\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_to_database(filename):\n",
    "    try:\n",
    "        # Create a connection to the database\n",
    "        connection = sqlite3.connect('data/wedge-to-the-database.db')\n",
    "        # Read the file\n",
    "        df = pd.read_csv(filename, sep=';')\n",
    "        # Get the table name from the file name\n",
    "        tablename = filename.split('/')[-1].split('.')[0]\n",
    "        # Put the dataframe into the sql database file\n",
    "        df.to_sql(tablename, connection, if_exists='replace', index=False)\n",
    "        # Memory management\n",
    "        del df, tablename\n",
    "        gc.collect()\n",
    "        # Success flag\n",
    "        print(\"Database table saved successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First File\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database table saved successfully.\n"
     ]
    }
   ],
   "source": [
    "write_file_to_database(filename1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second File\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database table saved successfully.\n"
     ]
    }
   ],
   "source": [
    "write_file_to_database(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third File\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/xfbtbhlj7376x9dz94q5nmbh0000gn/T/ipykernel_32559/1796808687.py:6: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database table saved successfully.\n"
     ]
    }
   ],
   "source": [
    "write_file_to_database(filename3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
